{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 多层感知器（神经网络）\n",
    "\n",
    "上一节我们学习的线性回归模型是单个神经元：\n",
    "\n",
    "计算输入特征的加权和\n",
    "\n",
    "然后使用一个激活函数（或传递函数）计算输出\n",
    "\n",
    "![](./imgs/3.1.png)\n",
    "\n",
    "--- \n",
    "\n",
    "多个神经元（多分类）\n",
    "\n",
    "![](./imgs/3.2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 单层神经元的缺陷\n",
    "\n",
    "1. 无法拟合 “异或” 运算\n",
    "\n",
    "异或问题看似简单，使用深层的神经元确实没有办法解决\n",
    "\n",
    "2. 神经元要求数据必须是线性可分的\n",
    "\n",
    "异或问题无法找到一条直线分割两个类\n",
    "\n",
    "这个问题是神经网络的发展停滞多年的主要原因。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 多层感知器\n",
    "\n",
    "生物的神经元一层一层连接起来，当神经信号达到某一个条件，这个神经元就会激活，然后继续传递信息下去。\n",
    "\n",
    "为了继续使用神经网络解决这种不具备线性可分性的问题，采取在神经网络的输入端和输出端之间插入更多神经元的方法。\n",
    "\n",
    "![](./imgs/3.3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 激活函数\n",
    "\n",
    "1. 最常用的 relu\n",
    "\n",
    "![](./imgs/3.4.png)\n",
    "\n",
    "2. sigmoid\n",
    "\n",
    "![](./imgs/3.5.png)\n",
    "\n",
    "3. tanh\n",
    "\n",
    "![](./imgs/3.6.png)\n",
    "\n",
    "4. Leak relu\n",
    "\n",
    "![](./imgs/3.7.png)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe32b506a41fd6e547419893516eb0475b202c6663ab6a0e062f20e9f3dc1f92"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
